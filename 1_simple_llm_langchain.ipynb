{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai langchain-community --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install python-dotenv --quiet\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write me a shell script to list the files in the current directory. \n",
      "Output the script as markdown code block\n"
     ]
    }
   ],
   "source": [
    "import _settings\n",
    "print(_settings.CHALLENGE_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "````shell\n",
      "#!/bin/bash\n",
      "# This script lists all the files in the current directory\n",
      "\n",
      "echo \"List of files in current directory:\"\n",
      "\n",
      "# Loop through all the files in the current directory\n",
      "for file in *\n",
      "do\n",
      "  # Check if file is a regular file\n",
      "  if [ -f \"$file\" ]\n",
      "  then\n",
      "    # Print file name\n",
      "    echo \"$file\"\n",
      "  fi\n",
      "done\n",
      "````\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "result = llm.invoke(_settings.CHALLENGE_PROMPT)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "[llm][start] - prompts: Write me a shell script to list the files in the current directory. \n",
      "Output the script as markdown code block\n",
      "[llm][new_token] \n",
      "\n",
      "\n",
      "[llm][new_token] ``\n",
      "[llm][new_token] `\n",
      "\n",
      "[llm][new_token] #!/\n",
      "[llm][new_token] bin\n",
      "[llm][new_token] /bash\n",
      "[llm][new_token] \n",
      "\n",
      "\n",
      "[llm][new_token] #\n",
      "[llm][new_token]  This\n",
      "[llm][new_token]  script\n",
      "[llm][new_token]  lists\n",
      "[llm][new_token]  all\n",
      "[llm][new_token]  the\n",
      "[llm][new_token]  files\n",
      "[llm][new_token]  in\n",
      "[llm][new_token]  the\n",
      "[llm][new_token]  current\n",
      "[llm][new_token]  directory\n",
      "[llm][new_token] \n",
      "\n",
      "\n",
      "[llm][new_token] #\n",
      "[llm][new_token]  Change\n",
      "[llm][new_token]  directory\n",
      "[llm][new_token]  to\n",
      "[llm][new_token]  current\n",
      "[llm][new_token]  directory\n",
      "[llm][new_token] \n",
      "\n",
      "[llm][new_token] cd\n",
      "[llm][new_token]  .\n",
      "\n",
      "\n",
      "[llm][new_token] #\n",
      "[llm][new_token]  Loop\n",
      "[llm][new_token]  through\n",
      "[llm][new_token]  all\n",
      "[llm][new_token]  files\n",
      "[llm][new_token]  in\n",
      "[llm][new_token]  current\n",
      "[llm][new_token]  directory\n",
      "[llm][new_token] \n",
      "\n",
      "[llm][new_token] for\n",
      "[llm][new_token]  file\n",
      "[llm][new_token]  in\n",
      "[llm][new_token]  *\n",
      "\n",
      "[llm][new_token] do\n",
      "[llm][new_token] \n",
      "\n",
      "[llm][new_token]    \n",
      "[llm][new_token]  #\n",
      "[llm][new_token]  Check\n",
      "[llm][new_token]  if\n",
      "[llm][new_token]  file\n",
      "[llm][new_token]  is\n",
      "[llm][new_token]  a\n",
      "[llm][new_token]  regular\n",
      "[llm][new_token]  file\n",
      "[llm][new_token] \n",
      "\n",
      "[llm][new_token]    \n",
      "[llm][new_token]  if\n",
      "[llm][new_token]  [\n",
      "[llm][new_token]  -\n",
      "[llm][new_token] f\n",
      "[llm][new_token]  \"$\n",
      "[llm][new_token] file\n",
      "[llm][new_token] \"\n",
      "[llm][new_token]  ]\n",
      "\n",
      "[llm][new_token]    \n",
      "[llm][new_token]  then\n",
      "[llm][new_token] \n",
      "\n",
      "[llm][new_token]        \n",
      "[llm][new_token]  #\n",
      "[llm][new_token]  Print\n",
      "[llm][new_token]  file\n",
      "[llm][new_token]  name\n",
      "[llm][new_token] \n",
      "        echo \"$file\"\n",
      "    fi\n",
      "done\n",
      "```\n",
      "\n",
      "\n",
      "[llm][new_token] To\n",
      "[llm][new_token]  run\n",
      "[llm][new_token]  this\n",
      "[llm][new_token]  script\n",
      "[llm][new_token] ,\n",
      "[llm][new_token]  save\n",
      "[llm][new_token]  it\n",
      "[llm][new_token]  as\n",
      "[llm][new_token]  a\n",
      "[llm][new_token]  .\n",
      "[llm][new_token] sh\n",
      "[llm][new_token]  file\n",
      "[llm][new_token]  and\n",
      "[llm][new_token]  execute\n",
      "[llm][new_token]  it\n",
      "[llm][new_token]  in\n",
      "[llm][new_token]  the\n",
      "[llm][new_token]  terminal\n",
      "[llm][new_token]  using\n",
      "[llm][new_token]  the\n",
      "[llm][new_token]  command\n",
      "[llm][new_token]  `\n",
      "[llm][new_token] ./\n",
      "[llm][new_token] script\n",
      "[llm][new_token] .sh\n",
      "[llm][new_token] `.\n",
      "[llm][new_token] \n",
      "\n",
      "=============\n",
      "[llm][end] - generation \n",
      "\n",
      "```\n",
      "#!/bin/bash\n",
      "\n",
      "# This script lists all the files in the current directory\n",
      "\n",
      "# Change directory to current directory\n",
      "cd .\n",
      "\n",
      "# Loop through all files in current directory\n",
      "for file in *\n",
      "do\n",
      "    # Check if file is a regular file\n",
      "    if [ -f \"$file\" ]\n",
      "    then\n",
      "        # Print file name\n",
      "        echo \"$file\"\n",
      "    fi\n",
      "done\n",
      "```\n",
      "\n",
      "To run this script, save it as a .sh file and execute it in the terminal using the command `./script.sh`.\n"
     ]
    }
   ],
   "source": [
    "# Use a callback handler\n",
    "from _callbacks import PrettyPrintCallbackHandler\n",
    "callback = PrettyPrintCallbackHandler()\n",
    "\n",
    "import _settings\n",
    "llm = OpenAI(streaming=True, temperature=0 , callbacks=[callback])\n",
    "result=llm.invoke(_settings.CHALLENGE_PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```\n",
      "#!/bin/bash\n",
      "\n",
      "# This script lists all the files in the current directory\n",
      "\n",
      "# Change directory to current directory\n",
      "cd .\n",
      "\n",
      "# Loop through all files in current directory\n",
      "for file in *\n",
      "do\n",
      "    # Check if file is a regular file\n",
      "    if [ -f \"$file\" ]\n",
      "    then\n",
      "        # Print file name\n",
      "        echo \"$file\"\n",
      "    fi\n",
      "done\n",
      "```\n",
      "\n",
      "To run this script, save it as a .sh file and execute it in the terminal using the command `./script.sh`.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n",
      "content='Here is a simple shell script that lists the files in the current directory:\\n```bash\\n# List files in the current directory\\nls -l\\n```\\nLet me explain what each line does:\\n\\n* `#` is a comment, indicating that everything after it is just a note for humans.\\n* `ls` is the command to list files and directories. The `-l` option tells `ls` to display detailed information about each file, including permissions, ownership, size, and modification time.\\n\\nTo use this script, save it to a file (e.g., `list_files.sh`) and then run it in your terminal using `bash list_files.sh`.' response_metadata={'model': 'llama3', 'created_at': '2024-06-15T07:36:48.600409Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3762907583, 'load_duration': 1337833292, 'prompt_eval_count': 32, 'prompt_eval_duration': 74742000, 'eval_count': 135, 'eval_duration': 2346626000} id='run-5ff06ad7-8e87-4f76-b23a-d0de61cf7427-0'\n"
     ]
    }
   ],
   "source": [
    "import _models, _settings\n",
    "print(_settings.MODEL_NAME)\n",
    "\n",
    "llm = _models.get_llm(_settings.MODEL_NAME,callbacks=[callback])\n",
    "result=llm.invoke(_settings.CHALLENGE_PROMPT)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mollama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOllama\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mget_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# base_url=\"...\",\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# organization=\"...\",\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# other params...\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m#if name == \"ollama\":\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# base_url=\"...\",\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# organization=\"...\",\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# other params...\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pycat _models.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-agents-DUG816Iy-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
